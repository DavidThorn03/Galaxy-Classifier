{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f580b28-8f5f-4348-8f65-0aad3e700cac",
      "metadata": {
        "id": "8f580b28-8f5f-4348-8f65-0aad3e700cac"
      },
      "source": [
        "## Base Line Model\n",
        "with Local Binary Pattern, Mobile Net 3 small with 1 added layer, flat architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6482c4d2-7cd7-471e-ba90-1931341dccb6",
      "metadata": {
        "id": "6482c4d2-7cd7-471e-ba90-1931341dccb6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b56a40-00c6-40ed-ad6b-70cb3df237d7",
      "metadata": {
        "id": "c1b56a40-00c6-40ed-ad6b-70cb3df237d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a1a421-d168-463a-e5b7-8a185ca017c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage import color\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044c180a-d6d9-4bf8-9545-4f4147733a61",
      "metadata": {
        "id": "044c180a-d6d9-4bf8-9545-4f4147733a61"
      },
      "source": [
        "### LBP Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53000783-494e-44d7-88c7-0900c1fdfafc",
      "metadata": {
        "id": "53000783-494e-44d7-88c7-0900c1fdfafc"
      },
      "outputs": [],
      "source": [
        "class LBPTransform:\n",
        "    def __init__(self, radius=3, n_points=None, method='uniform'):\n",
        "        self.radius = radius\n",
        "        self.n_points = n_points if n_points else 8 * radius\n",
        "        self.method = method\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if isinstance(img, Image.Image):\n",
        "            img = np.array(img)\n",
        "\n",
        "        if len(img.shape) == 3 :\n",
        "            gray = color.rgb2gray(img)\n",
        "        else:\n",
        "            gray = img\n",
        "\n",
        "        gray = (gray * 255).astype(np.uint8)\n",
        "\n",
        "        lbp = local_binary_pattern(gray, self.n_points, self.radius, self.method)\n",
        "\n",
        "        lbp = (lbp - lbp.min()) / (lbp.max() - lbp.min() + 1e-7)\n",
        "\n",
        "        lbp_3 = np.stack([lbp, lbp, lbp], axis=-1)\n",
        "\n",
        "        return lbp_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eec9685-e5ae-49e8-829f-0cbd70db40d1",
      "metadata": {
        "id": "2eec9685-e5ae-49e8-829f-0cbd70db40d1"
      },
      "source": [
        "### Make LBP Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5f0d63-4d34-44ea-aa4e-d50df0b88af1",
      "metadata": {
        "id": "af5f0d63-4d34-44ea-aa4e-d50df0b88af1"
      },
      "outputs": [],
      "source": [
        "def make_lbp_images(input_folder, output_folder, lbp_transformer):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    img_files = [f for f in os.listdir(input_folder) if f.endswith('.png')]\n",
        "\n",
        "    print(f\"Processing {len(img_files)} images from {input_folder}...\")\n",
        "    for i, fname in enumerate(img_files):\n",
        "        in_path = os.path.join(input_folder, fname)\n",
        "        out_path = os.path.join(output_folder, fname)\n",
        "\n",
        "        if os.path.exists(out_path):\n",
        "            continue\n",
        "\n",
        "        img = Image.open(in_path).convert('RGB')\n",
        "        lbp_img = lbp_transformer(img)\n",
        "\n",
        "        lbp_img_uint8 = (lbp_img * 255).astype(np.uint8)\n",
        "        Image.fromarray(lbp_img_uint8).save(out_path)\n",
        "\n",
        "    print(\"LBP preprocessing complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4556d2b0-340d-40b0-a13c-fa40daf91ce3",
      "metadata": {
        "id": "4556d2b0-340d-40b0-a13c-fa40daf91ce3"
      },
      "source": [
        "### Dataset Class\n",
        "Class for processing data and combining images with labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069073d5-c4b8-464d-ac66-2bcf6aee8479",
      "metadata": {
        "id": "069073d5-c4b8-464d-ac66-2bcf6aee8479"
      },
      "outputs": [],
      "source": [
        "class PGCDataset(Dataset):\n",
        "    def __init__(self, labels_df, img_folder, id_col='PGCname', label_col='T', transform=None):\n",
        "        self.labels_df = labels_df.reset_index(drop=True)\n",
        "        self.img_folder = img_folder\n",
        "        self.id_col = id_col\n",
        "        self.label_col = label_col\n",
        "        self.transform = transform\n",
        "\n",
        "        available_imgs = {f.replace('.png', '') for f in os.listdir(img_folder)\n",
        "                            if f.endswith('.png')}\n",
        "        self.labels_df = self.labels_df[self.labels_df[id_col].isin(available_imgs)].reset_index(drop=True)\n",
        "\n",
        "        print(f\"Dataset created with {len(self.labels_df)} imgs\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.labels_df.iloc[idx]\n",
        "\n",
        "        img_id = row[self.id_col]\n",
        "        img_path = os.path.join(self.img_folder, f\"{img_id}.png\")\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        label = torch.tensor(int(row[self.label_col]), dtype=torch.long)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label, img_id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c04eb15-ac7d-4317-b24a-66a69a4d59f5",
      "metadata": {
        "id": "1c04eb15-ac7d-4317-b24a-66a69a4d59f5"
      },
      "source": [
        "### Dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4244d3f0-97f7-43a9-b040-a0384a418bd2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4244d3f0-97f7-43a9-b040-a0384a418bd2",
        "outputId": "410ed83f-92c9-4f31-9faa-7cd8ced7767c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created with 3120 imgs\n",
            "Dataset created with 446 imgs\n",
            "Dataset created with 892 imgs\n"
          ]
        }
      ],
      "source": [
        "path = '/content/drive/Othercomputers/My laptop/Thesis/Galaxy-Classifier/'\n",
        "img_folder = path + '/images'\n",
        "lbp_img_folder = path + '/lbp_images'\n",
        "\n",
        "id_col = 'PGCname'\n",
        "label_col = 'T'\n",
        "\n",
        "img_size = 224\n",
        "\n",
        "lbp_trans = LBPTransform(5)\n",
        "\n",
        "labels_df = pd.read_csv(path + 'EFIGI_attributes.txt', sep=r'\\s+', comment='#')\n",
        "labels_df[label_col] = labels_df[label_col].replace({-3:-2, -1:-2}) # S0\n",
        "labels_df[label_col] = labels_df[label_col].replace({0:1, 2:1}) # Sa\n",
        "labels_df[label_col] = labels_df[label_col].replace({3:4}) # Sb\n",
        "labels_df[label_col] = labels_df[label_col].replace({5:6}) # Sc\n",
        "labels_df[label_col] = labels_df[label_col].replace({8:7, 9:7}) # Sd\n",
        "labels_df[label_col] = labels_df[label_col].replace({10:11}) # Irr\n",
        "\n",
        "labels_df[label_col] = labels_df[label_col].replace({-6:0, -5:1, -4:2, -2:3, 1:4, 4:5, 11:8}) # Adjust to 0 - 8\n",
        "\n",
        "\n",
        "train_df, test_df = train_test_split(labels_df, test_size=0.2, random_state=0, stratify=labels_df[label_col])\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.125, random_state=0, stratify=train_df[label_col])\n",
        "\n",
        "# use stratify sampling in training - write to csv file - - tocsv.pandas\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(180),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\"\"\"lbp_params = {'radius': 3, 'n_points': 24, 'method': 'uniform'}\n",
        "\n",
        "lbp_transform = LBPTransform(**lbp_params)\n",
        "\n",
        "make_lbp_images(img_folder, lbp_img_folder, lbp_transform)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "train_dataset = PGCDataset(\n",
        "    labels_df=train_df,\n",
        "    img_folder=img_folder,\n",
        "    id_col=id_col,\n",
        "    label_col=label_col,\n",
        "    transform=train_transform\n",
        ")\n",
        "val_dataset = PGCDataset(\n",
        "    labels_df=val_df,\n",
        "    img_folder=img_folder,\n",
        "    id_col=id_col,\n",
        "    label_col=label_col,\n",
        "    transform=test_transform\n",
        ")\n",
        "test_dataset = PGCDataset(\n",
        "    labels_df=test_df,\n",
        "    img_folder=img_folder,\n",
        "    id_col=id_col,\n",
        "    label_col=label_col,\n",
        "    transform=test_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e26d54c-8ece-4ca0-9511-ab7ce4c26a62",
      "metadata": {
        "id": "3e26d54c-8ece-4ca0-9511-ab7ce4c26a62"
      },
      "source": [
        "### Data loader\n",
        "loads data in batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ddb34a-a3e8-41b9-9a24-fb0d103c0b26",
      "metadata": {
        "id": "c7ddb34a-a3e8-41b9-9a24-fb0d103c0b26"
      },
      "outputs": [],
      "source": [
        "labels = train_df[label_col].values\n",
        "classes= np.unique(labels)\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
        "\n",
        "sample_weights = np.array([class_weights[np.where(classes == label)[0][0]] for label in labels])\n",
        "sample_weights = torch.from_numpy(sample_weights).float()\n",
        "\n",
        "# sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True) # worse for underrepresented classes and overall\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb3fa9ab-95ec-4320-bbd7-c4215834aaed",
      "metadata": {
        "id": "cb3fa9ab-95ec-4320-bbd7-c4215834aaed"
      },
      "source": [
        "### Hierarchical model\n",
        "using pretrained resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146c13bc-506b-49d8-8b6e-095e8e170259",
      "metadata": {
        "id": "146c13bc-506b-49d8-8b6e-095e8e170259"
      },
      "outputs": [],
      "source": [
        "class HierarchicalResNet(nn.Module):\n",
        "  def __init__(self, num_coarse, fine_per_coarse, freeze_backbone=False):\n",
        "    super(HierarchicalResNet, self).__init__()\n",
        "    # get model\n",
        "    resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    # freeze layers\n",
        "    for param in resnet.parameters():\n",
        "      param.requires_grad = not freeze_backbone\n",
        "\n",
        "    # remove the final full connect layer\n",
        "    self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "    in_features = resnet.fc.in_features\n",
        "\n",
        "    self.num_coarse = num_coarse\n",
        "    self.fine_per_coarse = fine_per_coarse\n",
        "\n",
        "    # classifier heads\n",
        "    self.coarse_classifier = nn.Sequential(nn.Linear(in_features, num_coarse))\n",
        "    self.fine_classifiers = nn.ModuleList([nn.Linear(in_features, num_fine) for num_fine in fine_per_coarse])\n",
        "\n",
        "    self.fine_to_coarse = {}\n",
        "    self.coarse_to_fine = {}\n",
        "\n",
        "    # build mapping\n",
        "    fine_id = 0\n",
        "\n",
        "    for coarse_id, num_fine in enumerate(fine_per_coarse):\n",
        "      self.coarse_to_fine[coarse_id] = []\n",
        "      for local_fine_id in range(num_fine):\n",
        "        self.fine_to_coarse[fine_id] = (coarse_id, local_fine_id)\n",
        "        self.coarse_to_fine[coarse_id].append(fine_id)\n",
        "        fine_id += 1\n",
        "\n",
        "    self.total_fine_classes = sum(fine_per_coarse)\n",
        "\n",
        "\n",
        "  def forward(self, x, return_type='train'):\n",
        "    features = self.backbone(x)\n",
        "    features = torch.flatten(features, 1)\n",
        "\n",
        "    # get predictions from features\n",
        "    coarse_output = self.coarse_classifier(features)\n",
        "    fine_output = [classifier(features) for classifier in self.fine_classifiers]\n",
        "\n",
        "    if return_type == 'train':\n",
        "      return coarse_output, fine_output, features\n",
        "\n",
        "    elif return_type == 'test':\n",
        "      return self.joint_prob(coarse_output, fine_output)\n",
        "\n",
        "\n",
        "  def joint_prob(self, coarse_output, fine_output):\n",
        "    batch = coarse_output.size(0)\n",
        "    device = coarse_output.device\n",
        "\n",
        "    coarse_probs = F.softmax(coarse_output, dim=1)\n",
        "\n",
        "    fine_cond_probs = [\n",
        "        F.softmax(logits, dim=1) for logits in fine_output\n",
        "    ]\n",
        "\n",
        "    fine_probs = torch.zeros((batch, self.total_fine_classes), device=device)\n",
        "\n",
        "    fine_id = 0\n",
        "    for coarse_id, cond_probs in enumerate(fine_cond_probs):\n",
        "      num_fine_in_coarse = cond_probs.size(1)\n",
        "\n",
        "      coarse_probs_per_class = coarse_probs[:, coarse_id].unsqueeze(1)\n",
        "      joint_prob = coarse_probs_per_class * cond_probs\n",
        "\n",
        "      fine_probs[:, fine_id:fine_id + num_fine_in_coarse] = joint_prob\n",
        "\n",
        "      fine_id += num_fine_in_coarse\n",
        "\n",
        "    return coarse_probs, fine_probs, fine_cond_probs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarchical Loss\n",
        "using cross entropy"
      ],
      "metadata": {
        "id": "zWmIxHc3JvDE"
      },
      "id": "zWmIxHc3JvDE"
    },
    {
      "cell_type": "code",
      "source": [
        "class HierarchicalLoss(nn.Module):\n",
        "  def __init__(self, fine_per_coarse, fine_weights=None, coarse_weights=None):\n",
        "    super(HierarchicalLoss, self).__init__()\n",
        "    # hash map of fine - course\n",
        "    self.fine_per_coarse = fine_per_coarse\n",
        "\n",
        "    self.loss_coarse = nn.CrossEntropyLoss(weight=coarse_weights)\n",
        "\n",
        "    if fine_weights is not None:\n",
        "      self.loss_fine = nn.ModuleList()\n",
        "      start_id = 0\n",
        "      for num_fine in fine_per_coarse:\n",
        "        coarse_weights = fine_weights[start_id:start_id + num_fine]\n",
        "        self.loss_fine.append(nn.CrossEntropyLoss(weight=coarse_weights))\n",
        "        start_id += num_fine\n",
        "    else:\n",
        "      self.loss_fine = nn.ModuleList([nn.CrossEntropyLoss() for _ in fine_per_coarse])\n",
        "\n",
        "    # tensor for mapping\n",
        "    self.fine_to_coarse = {}\n",
        "    fine_id = 0\n",
        "    for coarse_id, num_fine in enumerate(fine_per_coarse):\n",
        "      for local_fine_id in range(num_fine):\n",
        "        self.fine_to_coarse[fine_id] = (coarse_id, local_fine_id)\n",
        "        fine_id += 1\n",
        "\n",
        "\n",
        "  def forward(self, coarse_logits, fine_logits, fine_labels):\n",
        "    batch = fine_labels.size(0)\n",
        "    device = fine_labels.device\n",
        "\n",
        "    coarse_labels = torch.zeros(batch, dtype=torch.long, device=device)\n",
        "    local_fine = torch.zeros(batch, dtype=torch.long, device=device)\n",
        "\n",
        "    for i, global_fine in enumerate(fine_labels):\n",
        "      coarse_id, local_fine_id = self.fine_to_coarse[global_fine.item()]\n",
        "      coarse_labels[i] = coarse_id\n",
        "      local_fine[i] = local_fine_id\n",
        "\n",
        "    coarse_loss = self.loss_coarse(coarse_logits, coarse_labels)\n",
        "\n",
        "    fine_loss = 0\n",
        "    for i in range(batch):\n",
        "      coarse_id = coarse_labels[i].item()\n",
        "\n",
        "      local_fine_logits = fine_logits[coarse_id][i].unsqueeze(0)\n",
        "      fine_label = local_fine[i].unsqueeze(0)\n",
        "      fine_loss += self.loss_fine[coarse_id](local_fine_logits, fine_label)\n",
        "\n",
        "    fine_loss /= batch\n",
        "\n",
        "    loss = coarse_loss + fine_loss\n",
        "\n",
        "    return loss, coarse_loss, fine_loss\n"
      ],
      "metadata": {
        "id": "MKewVoSLJmK2"
      },
      "id": "MKewVoSLJmK2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate class weights"
      ],
      "metadata": {
        "id": "xd3-ttA8KBK3"
      },
      "id": "xd3-ttA8KBK3"
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_weights(labels, fine_per_coarse, device='cpu'):\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    fine_to_coarse_mapping = {}\n",
        "    fine_id = 0\n",
        "    for coarse_id, num_fine in enumerate(fine_per_coarse):\n",
        "      for local_fine_id in range(num_fine):\n",
        "        fine_to_coarse_mapping[fine_id] = coarse_id\n",
        "        fine_id += 1\n",
        "\n",
        "    fine_classes = np.unique(labels)\n",
        "    fine_weights = compute_class_weight('balanced', classes=fine_classes, y=labels)\n",
        "\n",
        "    total_fine_classes = sum(fine_per_coarse)\n",
        "    fine_weights_full = torch.ones(total_fine_classes, dtype=torch.float, device=device)\n",
        "    for i, class_id in enumerate(fine_classes):\n",
        "        fine_weights_full[class_id] = fine_weights[i]\n",
        "\n",
        "    coarse_labels = np.array([fine_to_coarse_mapping[label] for label in labels])\n",
        "    coarse_classes = np.unique(coarse_labels)\n",
        "    coarse_weights = compute_class_weight('balanced', classes=coarse_classes, y=coarse_labels)\n",
        "\n",
        "    num_coarse_classes = len(fine_per_coarse)\n",
        "    coarse_weights_full = torch.ones(num_coarse_classes, dtype=torch.float, device=device)\n",
        "    for i, class_id in enumerate(coarse_classes):\n",
        "        coarse_weights_full[class_id] = coarse_weights[i]\n",
        "\n",
        "    return fine_weights_full, coarse_weights_full"
      ],
      "metadata": {
        "id": "B0JYvXK2KHZr"
      },
      "id": "B0JYvXK2KHZr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2ea6a124-037f-40b4-8fe1-9d2befb73377",
      "metadata": {
        "id": "2ea6a124-037f-40b4-8fe1-9d2befb73377"
      },
      "source": [
        "## Train/test model methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0461f6ae-cb64-45ca-8c09-9b12f919b8ee",
      "metadata": {
        "id": "0461f6ae-cb64-45ca-8c09-9b12f919b8ee"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss, running_coarse, running_fine = 0.0, 0.0, 0.0\n",
        "    correct_coarse, correct_fine = 0, 0\n",
        "    total = 0\n",
        "\n",
        "    for img, labels, ids in dataloader:\n",
        "        img = img.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        coarse_logits, fine_logits, _ = model(img, return_type='train')\n",
        "\n",
        "        loss, coarse_loss, fine_loss = criterion(coarse_logits, fine_logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_coarse += coarse_loss.item()\n",
        "        running_fine += fine_loss.item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          coarse_probs, fine_probs, _ = model(img, return_type='test')\n",
        "          predict_coarse = coarse_probs.argmax(1)\n",
        "          predict_fine = fine_probs.argmax(1)\n",
        "\n",
        "          coarse_labels = torch.tensor([\n",
        "              criterion.fine_to_coarse[label.item()][0]\n",
        "              for label in labels\n",
        "          ], device=device)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct_fine += (predict_fine == labels).sum().item()\n",
        "        correct_coarse += (predict_coarse == coarse_labels).sum().item()\n",
        "\n",
        "\n",
        "        print(\".\", end=\"\")\n",
        "    print(\"\")\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_coarse = running_coarse / len(dataloader)\n",
        "    epoch_fine = running_fine / len(dataloader)\n",
        "\n",
        "    epoch_acc_fine = 100.0 * correct_fine / total\n",
        "    epoch_acc_coarse = 100.0 * correct_coarse / total\n",
        "\n",
        "    return {\n",
        "        'total_loss': epoch_loss,\n",
        "        'coarse_loss': epoch_coarse,\n",
        "        'fine_loss': epoch_fine,\n",
        "        'fine_acc': epoch_acc_fine,\n",
        "        'coarse_acc': epoch_acc_coarse\n",
        "    }\n",
        "\n",
        "def valid(model, dataloader, device, loss_fn, use_weighted=False):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "\n",
        "    correct_fine, correct_coarse = 0, 0\n",
        "\n",
        "    all_preds_fine = []\n",
        "    all_preds_coarse = []\n",
        "    all_labels_fine = []\n",
        "    all_labels_coarse = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y, _ in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "\n",
        "            coarse_logits, fine_logits, _ = model(X, return_type='train')\n",
        "\n",
        "            loss, _, _ = loss_fn(coarse_logits, fine_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            coarse_probs, fine_probs, _ = model(X, return_type='test')\n",
        "\n",
        "            predicted_coarse = coarse_probs.argmax(1)\n",
        "            predicted_fine = fine_probs.argmax(1)\n",
        "\n",
        "            coarse_labels = torch.tensor([\n",
        "                loss_fn.fine_to_coarse[label.item()][0]\n",
        "                for label in y\n",
        "            ], device=device)\n",
        "\n",
        "            correct_fine += (predicted_fine == y).type(torch.float).sum().item()\n",
        "            correct_coarse += (predicted_coarse == coarse_labels).type(torch.float).sum().item()\n",
        "\n",
        "            all_preds_fine.extend(predicted_fine.cpu().numpy())\n",
        "            all_preds_coarse.extend(predicted_coarse.cpu().numpy())\n",
        "            all_labels_fine.extend(y.cpu().numpy())\n",
        "            all_labels_coarse.extend(coarse_labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct_fine /= size\n",
        "    correct_coarse /= size\n",
        "\n",
        "    return {\n",
        "        'total_loss': test_loss,\n",
        "        'fine_acc': correct_fine * 100,\n",
        "        'coarse_acc': correct_coarse * 100,\n",
        "        'predictions': {\n",
        "            'fine': all_preds_fine,\n",
        "            'coarse': all_preds_coarse,\n",
        "            'labels_fine': all_labels_fine,\n",
        "            'labels_coarse': all_labels_coarse\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "def test(model, dataloader, device, loss_fn, use_weighted=False):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "\n",
        "    correct_fine, correct_coarse = 0, 0\n",
        "\n",
        "    all_preds_fine = []\n",
        "    all_preds_coarse = []\n",
        "    all_labels_fine = []\n",
        "    all_labels_coarse = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y, _ in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "\n",
        "            coarse_logits, fine_logits, _ = model(X, return_type='train')\n",
        "\n",
        "            loss, _, _ = loss_fn(coarse_logits, fine_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            coarse_probs, fine_probs, _ = model(X, return_type='test')\n",
        "\n",
        "            predicted_coarse = coarse_probs.argmax(1)\n",
        "            predicted_fine = fine_probs.argmax(1)\n",
        "\n",
        "            coarse_labels = torch.tensor([\n",
        "                loss_fn.fine_to_coarse[label.item()][0]\n",
        "                for label in y\n",
        "            ], device=device)\n",
        "\n",
        "            correct_fine += (predicted_fine == y).type(torch.float).sum().item()\n",
        "            correct_coarse += (predicted_coarse == coarse_labels).type(torch.float).sum().item()\n",
        "\n",
        "            all_preds_fine.extend(predicted_fine.cpu().numpy())\n",
        "            all_preds_coarse.extend(predicted_coarse.cpu().numpy())\n",
        "            all_labels_fine.extend(y.cpu().numpy())\n",
        "            all_labels_coarse.extend(coarse_labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct_fine /= size\n",
        "    correct_coarse /= size\n",
        "\n",
        "    print(\"Fine classes\")\n",
        "    print(classification_report(all_labels_fine, all_preds_fine, digits=4))\n",
        "\n",
        "    print(\"Coarse classes\")\n",
        "    print(classification_report(all_labels_coarse, all_preds_coarse, digits=4))\n",
        "\n",
        "    return {\n",
        "        'total_loss': test_loss,\n",
        "        'fine_acc': correct_fine * 100,\n",
        "        'coarse_acc': correct_coarse * 100\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "sRDJ8Ph-vuwQ"
      },
      "id": "sRDJ8Ph-vuwQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46069f7-c98f-4c8d-845a-e577489d23fd",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a46069f7-c98f-4c8d-845a-e577489d23fd",
        "outputId": "0606d1aa-228d-4394-b17c-0d1510dac173",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/50\n",
            ".................................................\n",
            "Train - Loss: 2.1482, Fine Acc: 19.33%, Coarse Acc: 53.37%\n",
            "Valid - Loss: 1.7117, Fine Acc: 27.58%, Coarse Acc: 69.51%\n",
            "Epoch 2/50\n",
            ".................................................\n",
            "Train - Loss: 1.7622, Fine Acc: 31.35%, Coarse Acc: 66.54%\n",
            "Valid - Loss: 1.6215, Fine Acc: 31.39%, Coarse Acc: 69.28%\n",
            "Epoch 3/50\n",
            ".................................................\n",
            "Train - Loss: 1.6361, Fine Acc: 36.83%, Coarse Acc: 68.11%\n",
            "Valid - Loss: 1.4929, Fine Acc: 37.67%, Coarse Acc: 71.75%\n",
            "Epoch 4/50\n",
            ".................................................\n",
            "Train - Loss: 1.5711, Fine Acc: 39.42%, Coarse Acc: 70.93%\n",
            "Valid - Loss: 1.4063, Fine Acc: 40.13%, Coarse Acc: 73.99%\n",
            "Epoch 5/50\n",
            ".................................................\n",
            "Train - Loss: 1.5326, Fine Acc: 40.77%, Coarse Acc: 70.58%\n",
            "Valid - Loss: 1.4546, Fine Acc: 40.13%, Coarse Acc: 69.96%\n",
            "Epoch 6/50\n",
            ".................................................\n",
            "Train - Loss: 1.5034, Fine Acc: 42.95%, Coarse Acc: 71.03%\n",
            "Valid - Loss: 1.3052, Fine Acc: 45.29%, Coarse Acc: 77.35%\n",
            "Epoch 7/50\n",
            ".................................................\n",
            "Train - Loss: 1.4596, Fine Acc: 42.47%, Coarse Acc: 70.80%\n",
            "Valid - Loss: 1.4083, Fine Acc: 42.15%, Coarse Acc: 71.75%\n",
            "Epoch 8/50\n",
            ".................................................\n",
            "Train - Loss: 1.4703, Fine Acc: 42.34%, Coarse Acc: 69.97%\n",
            "Valid - Loss: 1.3835, Fine Acc: 43.72%, Coarse Acc: 74.22%\n",
            "Epoch 9/50\n",
            ".................................................\n",
            "Train - Loss: 1.4372, Fine Acc: 43.59%, Coarse Acc: 71.35%\n",
            "Valid - Loss: 1.3467, Fine Acc: 42.60%, Coarse Acc: 74.44%\n",
            "Epoch 10/50\n",
            ".................................................\n",
            "Train - Loss: 1.4213, Fine Acc: 44.49%, Coarse Acc: 71.15%\n",
            "Valid - Loss: 1.2403, Fine Acc: 47.98%, Coarse Acc: 78.48%\n",
            "Epoch 11/50\n",
            ".................................................\n",
            "Train - Loss: 1.4033, Fine Acc: 44.97%, Coarse Acc: 73.14%\n",
            "Valid - Loss: 1.3434, Fine Acc: 42.38%, Coarse Acc: 74.66%\n",
            "Epoch 12/50\n",
            ".................................................\n",
            "Train - Loss: 1.3806, Fine Acc: 46.06%, Coarse Acc: 71.96%\n",
            "Valid - Loss: 1.3357, Fine Acc: 42.83%, Coarse Acc: 72.87%\n",
            "Epoch 13/50\n",
            "..........................."
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4010633448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     print(f\"Train - Loss: {train_metrics['total_loss']:.4f}, \"\n\u001b[1;32m     29\u001b[0m           \u001b[0;34mf\"Fine Acc: {train_metrics['fine_acc']:.2f}%, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2881500151.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4011594500.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimg_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{img_id}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_name = 'parent_base.pth'\n",
        "num_coarse = 4\n",
        "num_fine = 9\n",
        "\n",
        "fine_per_coarse = [3, 1, 4, 1]\n",
        "\n",
        "model = HierarchicalResNet(num_coarse, fine_per_coarse, freeze_backbone=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "fine_weights, coarse_weights = calculate_class_weights(train_df[label_col], fine_per_coarse, device)\n",
        "\n",
        "train_criterion = HierarchicalLoss(fine_per_coarse, fine_weights, coarse_weights)\n",
        "test_criterion = HierarchicalLoss(fine_per_coarse)\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
        "\n",
        "best_acc = 0.0\n",
        "\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    train_metrics = train_one_epoch(model, train_loader, train_criterion, optimizer, device)\n",
        "    print(f\"Train - Loss: {train_metrics['total_loss']:.4f}, \"\n",
        "          f\"Fine Acc: {train_metrics['fine_acc']:.2f}%, \"\n",
        "          f\"Coarse Acc: {train_metrics['coarse_acc']:.2f}%\")\n",
        "\n",
        "    valid_metrics = valid(model, val_loader, device, test_criterion)\n",
        "    print(f\"Valid - Loss: {valid_metrics['total_loss']:.4f}, \"\n",
        "          f\"Fine Acc: {valid_metrics['fine_acc']:.2f}%, \"\n",
        "          f\"Coarse Acc: {valid_metrics['coarse_acc']:.2f}%\")\n",
        "\n",
        "    scheduler.step(valid_metrics['total_loss'])\n",
        "\n",
        "    if valid_metrics['fine_acc'] > best_acc:\n",
        "        best_acc = valid_metrics['fine_acc']\n",
        "        torch.save(model.state_dict(), path + model_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test model"
      ],
      "metadata": {
        "id": "Ci11a7Nkv5ZZ"
      },
      "id": "Ci11a7Nkv5ZZ"
    },
    {
      "cell_type": "code",
      "source": [
        "model = HierarchicalResNet(num_coarse, fine_per_coarse, freeze_backbone=True)\n",
        "\n",
        "model.load_state_dict(torch.load(path + model_name))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "test_metrics = test(model, test_loader, device, test_criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhNNyfh5v8Yn",
        "outputId": "31f8bee6-f929-4026-b485-2441e819c230"
      },
      "id": "KhNNyfh5v8Yn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine classes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7500    0.7500    0.7500         4\n",
            "           1     0.7213    0.9778    0.8302        45\n",
            "           2     0.8333    0.5556    0.6667         9\n",
            "           3     0.7500    0.8411    0.7930       107\n",
            "           4     0.7938    0.5704    0.6638       135\n",
            "           5     0.7157    0.7374    0.7264       198\n",
            "           6     0.6543    0.7067    0.6795       150\n",
            "           7     0.8642    0.7735    0.8163       181\n",
            "           8     0.7500    0.9048    0.8201        63\n",
            "\n",
            "    accuracy                         0.7489       892\n",
            "   macro avg     0.7592    0.7575    0.7495       892\n",
            "weighted avg     0.7555    0.7489    0.7466       892\n",
            "\n",
            "Coarse classes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7778    0.9655    0.8615        58\n",
            "           1     0.7563    0.8411    0.7965       107\n",
            "           2     0.9872    0.9322    0.9589       664\n",
            "           3     0.7568    0.8889    0.8175        63\n",
            "\n",
            "    accuracy                         0.9204       892\n",
            "   macro avg     0.8195    0.9069    0.8586       892\n",
            "weighted avg     0.9296    0.9204    0.9231       892\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}