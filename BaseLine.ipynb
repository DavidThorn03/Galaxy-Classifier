{"cells":[{"cell_type":"markdown","id":"8f580b28-8f5f-4348-8f65-0aad3e700cac","metadata":{"id":"8f580b28-8f5f-4348-8f65-0aad3e700cac"},"source":["## Base Line Model\n","with Local Binary Pattern, Mobile Net 3 small with 1 added layer, flat architecture."]},{"cell_type":"markdown","id":"6482c4d2-7cd7-471e-ba90-1931341dccb6","metadata":{"id":"6482c4d2-7cd7-471e-ba90-1931341dccb6"},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"id":"c1b56a40-00c6-40ed-ad6b-70cb3df237d7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27785,"status":"ok","timestamp":1763460549362,"user":{"displayName":"David Thornton","userId":"09711607386999570486"},"user_tz":0},"id":"c1b56a40-00c6-40ed-ad6b-70cb3df237d7","outputId":"ef067380-2442-4c96-91d7-04818ca39569"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import pandas as pd\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from skimage.feature import local_binary_pattern\n","from skimage import color\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import classification_report\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"044c180a-d6d9-4bf8-9545-4f4147733a61","metadata":{"id":"044c180a-d6d9-4bf8-9545-4f4147733a61"},"source":["### LBP Transform"]},{"cell_type":"code","execution_count":null,"id":"53000783-494e-44d7-88c7-0900c1fdfafc","metadata":{"id":"53000783-494e-44d7-88c7-0900c1fdfafc"},"outputs":[],"source":["class LBPTransform:\n","    def __init__(self, radius=3, n_points=None, method='uniform'):\n","        self.radius = radius\n","        self.n_points = n_points if n_points else 8 * radius\n","        self.method = method\n","\n","    def __call__(self, img):\n","        if isinstance(img, Image.Image):\n","            img = np.array(img)\n","\n","        if len(img.shape) == 3 :\n","            gray = color.rgb2gray(img)\n","        else:\n","            gray = img\n","\n","        gray = (gray * 255).astype(np.uint8)\n","\n","        lbp = local_binary_pattern(gray, self.n_points, self.radius, self.method)\n","\n","        lbp = (lbp - lbp.min()) / (lbp.max() - lbp.min() + 1e-7)\n","\n","        lbp_3 = np.stack([lbp, lbp, lbp], axis=-1)\n","\n","        return lbp_3"]},{"cell_type":"markdown","id":"2eec9685-e5ae-49e8-829f-0cbd70db40d1","metadata":{"id":"2eec9685-e5ae-49e8-829f-0cbd70db40d1"},"source":["### Make LBP Images"]},{"cell_type":"code","execution_count":null,"id":"af5f0d63-4d34-44ea-aa4e-d50df0b88af1","metadata":{"id":"af5f0d63-4d34-44ea-aa4e-d50df0b88af1"},"outputs":[],"source":["def make_lbp_images(input_folder, output_folder, lbp_transformer):\n","    os.makedirs(output_folder, exist_ok=True)\n","    img_files = [f for f in os.listdir(input_folder) if f.endswith('.png')]\n","\n","    print(f\"Processing {len(img_files)} images from {input_folder}...\")\n","    for i, fname in enumerate(img_files):\n","        in_path = os.path.join(input_folder, fname)\n","        out_path = os.path.join(output_folder, fname)\n","\n","        if os.path.exists(out_path):\n","            continue\n","\n","        img = Image.open(in_path).convert('RGB')\n","        lbp_img = lbp_transformer(img)\n","\n","        lbp_img_uint8 = (lbp_img * 255).astype(np.uint8)\n","        Image.fromarray(lbp_img_uint8).save(out_path)\n","\n","    print(\"LBP preprocessing complete.\")"]},{"cell_type":"markdown","id":"4556d2b0-340d-40b0-a13c-fa40daf91ce3","metadata":{"id":"4556d2b0-340d-40b0-a13c-fa40daf91ce3"},"source":["### Dataset Class\n","Class for processing data and combining images with labels"]},{"cell_type":"code","execution_count":null,"id":"069073d5-c4b8-464d-ac66-2bcf6aee8479","metadata":{"id":"069073d5-c4b8-464d-ac66-2bcf6aee8479"},"outputs":[],"source":["class PGCDataset(Dataset):\n","    def __init__(self, labels_df, img_folder, id_col='PGCname', label_col='T', transform=None):\n","        self.labels_df = labels_df.reset_index(drop=True)\n","        self.img_folder = img_folder\n","        self.id_col = id_col\n","        self.label_col = label_col\n","        self.transform = transform\n","\n","        available_imgs = {f.replace('.png', '') for f in os.listdir(img_folder)\n","                            if f.endswith('.png')}\n","        self.labels_df = self.labels_df[self.labels_df[id_col].isin(available_imgs)].reset_index(drop=True)\n","\n","        print(f\"Dataset created with {len(self.labels_df)} imgs\")\n","\n","    def __len__(self):\n","        return len(self.labels_df)\n","\n","    def __getitem__(self, idx):\n","        row = self.labels_df.iloc[idx]\n","\n","        img_id = row[self.id_col]\n","        img_path = os.path.join(self.img_folder, f\"{img_id}.png\")\n","        img = Image.open(img_path).convert('RGB')\n","\n","        label = torch.tensor(int(row[self.label_col]), dtype=torch.long)\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label, img_id"]},{"cell_type":"markdown","id":"1c04eb15-ac7d-4317-b24a-66a69a4d59f5","metadata":{"id":"1c04eb15-ac7d-4317-b24a-66a69a4d59f5"},"source":["### Dataset creation"]},{"cell_type":"code","execution_count":null,"id":"4244d3f0-97f7-43a9-b040-a0384a418bd2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16595,"status":"ok","timestamp":1763460566020,"user":{"displayName":"David Thornton","userId":"09711607386999570486"},"user_tz":0},"id":"4244d3f0-97f7-43a9-b040-a0384a418bd2","outputId":"7e166448-b417-4636-84bb-94aa728e2a82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset created with 3120 imgs\n","Dataset created with 446 imgs\n","Dataset created with 892 imgs\n"]}],"source":["path = '/content/drive/Othercomputers/My laptop/Thesis/'\n","img_folder = path + '/images'\n","lbp_img_folder = path + '/lbp_images'\n","\n","id_col = 'PGCname'\n","label_col = 'T'\n","\n","img_size = 224\n","\n","labels_df = pd.read_csv(path + 'EFIGI_attributes.txt', sep=r'\\s+', comment='#')\n","#labels_df[label_col] = labels_df[label_col].replace({-6:-4, -5:-4}) # E\n","labels_df[label_col] = labels_df[label_col].replace({-3:-2, -1:-2}) # S0\n","labels_df[label_col] = labels_df[label_col].replace({0:1, 2:1}) # Sa\n","labels_df[label_col] = labels_df[label_col].replace({3:4}) # Sb\n","labels_df[label_col] = labels_df[label_col].replace({5:6}) # Sc\n","labels_df[label_col] = labels_df[label_col].replace({8:7, 9:7}) # Sd\n","labels_df[label_col] = labels_df[label_col].replace({10:11}) # Irr\n","\n","labels_df[label_col] = labels_df[label_col].replace({-6:0, -5:1, -4:2, -2:3, 1:4, 4:5, 11:8}) # Adjust to 0 - 8\n","#labels_df[label_col] = labels_df[label_col].replace({-4:0, -2:1, 1:2, 4:3, 6:4, 7:5, 11:6}) # Adjust to 0 - 6\n","\n","\n","train_df, test_df = train_test_split(labels_df, test_size=0.2, random_state=0, stratify=labels_df[label_col])\n","train_df, val_df = train_test_split(train_df, test_size=0.125, random_state=0, stratify=train_df[label_col])\n","\n","# use stratify sampling in training - write to csv file - - tocsv.pandas\n","\n","\n","train_transform = transforms.Compose([\n","    transforms.RandomRotation(180),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.Resize((img_size, img_size)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((img_size, img_size)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","\"\"\"lbp_params = {'radius': 3, 'n_points': 24, 'method': 'uniform'}\n","\n","lbp_transform = LBPTransform(**lbp_params)\n","\n","make_lbp_images(img_folder, lbp_img_folder, lbp_transform)\n","\"\"\"\n","\n","\n","train_dataset = PGCDataset(\n","    labels_df=train_df,\n","    img_folder=img_folder,\n","    id_col=id_col,\n","    label_col=label_col,\n","    transform=train_transform\n",")\n","val_dataset = PGCDataset(\n","    labels_df=val_df,\n","    img_folder=img_folder,\n","    id_col=id_col,\n","    label_col=label_col,\n","    transform=test_transform\n",")\n","test_dataset = PGCDataset(\n","    labels_df=test_df,\n","    img_folder=img_folder,\n","    id_col=id_col,\n","    label_col=label_col,\n","    transform=test_transform\n",")"]},{"cell_type":"markdown","id":"3e26d54c-8ece-4ca0-9511-ab7ce4c26a62","metadata":{"id":"3e26d54c-8ece-4ca0-9511-ab7ce4c26a62"},"source":["### Data loader\n","loads data in batches"]},{"cell_type":"code","execution_count":null,"id":"c7ddb34a-a3e8-41b9-9a24-fb0d103c0b26","metadata":{"id":"c7ddb34a-a3e8-41b9-9a24-fb0d103c0b26"},"outputs":[],"source":["labels = train_df[label_col].values\n","classes= np.unique(labels)\n","class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n","\n","sample_weights = np.array([class_weights[np.where(classes == label)[0][0]] for label in labels])\n","sample_weights = torch.from_numpy(sample_weights).float()\n","\n","sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=64,\n","    shuffle=True,\n","    num_workers=0,\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=0,\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=0\n",")"]},{"cell_type":"markdown","id":"cb3fa9ab-95ec-4320-bbd7-c4215834aaed","metadata":{"id":"cb3fa9ab-95ec-4320-bbd7-c4215834aaed"},"source":["### Make model\n","using pretrained resnet18"]},{"cell_type":"code","execution_count":null,"id":"146c13bc-506b-49d8-8b6e-095e8e170259","metadata":{"id":"146c13bc-506b-49d8-8b6e-095e8e170259"},"outputs":[],"source":["def resnet_model(num_classes, freeze_backbone=True):\n","    model = models.resnet18(weights='IMAGENET1K_V1')\n","    for param in model.parameters():\n","        param.requires_grad = not freeze_backbone\n","    in_features = model.fc.in_features\n","    model.fc = nn.Linear(in_features, num_classes)\n","    return model"]},{"cell_type":"markdown","id":"2ea6a124-037f-40b4-8fe1-9d2befb73377","metadata":{"id":"2ea6a124-037f-40b4-8fe1-9d2befb73377"},"source":["## Train/test model methods"]},{"cell_type":"code","execution_count":null,"id":"0461f6ae-cb64-45ca-8c09-9b12f919b8ee","metadata":{"id":"0461f6ae-cb64-45ca-8c09-9b12f919b8ee"},"outputs":[],"source":["def train_one_epoch(model, dataloader, criterion, optimizer, device, scaler=None):\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","\n","    for img, labels, ids in dataloader:\n","        img = img.to(device, non_blocking=True)\n","        labels = labels.to(device, non_blocking=True)\n","        optimizer.zero_grad()\n","\n","        outputs = model(img)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += predicted.eq(labels).sum().item()\n","        print(\".\", end=\"\")\n","    print(\"\")\n","\n","    epoch_loss = running_loss / len(dataloader)\n","    epoch_acc = 100.0 * correct / total\n","    return epoch_loss, epoch_acc\n","\n","def valid(model, dataloader, device, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for X, y, _ in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","            all_preds.extend(pred.argmax(1).cpu().numpy())\n","            all_labels.extend(y.cpu().numpy())\n","\n","    test_loss /= num_batches\n","    correct /= size\n","    return test_loss, correct * 100\n","\n","\n","def test(model, dataloader, device, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for X, y, _ in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","            all_preds.extend(pred.argmax(1).cpu().numpy())\n","            all_labels.extend(y.cpu().numpy())\n","\n","    all_preds = np.array(all_preds)\n","    all_labels = np.array(all_labels)\n","\n","    test_loss /= num_batches\n","    correct /= size\n","\n","    print(classification_report(all_labels, all_preds, digits=4))\n","\n","    return test_loss, correct * 100\n"]},{"cell_type":"markdown","id":"sRDJ8Ph-vuwQ","metadata":{"id":"sRDJ8Ph-vuwQ"},"source":["## Train model"]},{"cell_type":"code","execution_count":null,"id":"a46069f7-c98f-4c8d-845a-e577489d23fd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":661,"status":"error","timestamp":1763460572208,"user":{"displayName":"David Thornton","userId":"09711607386999570486"},"user_tz":0},"id":"a46069f7-c98f-4c8d-845a-e577489d23fd","jp-MarkdownHeadingCollapsed":true,"outputId":"4d18d335-ea90-495d-d540-65913858559d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3259855750.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-360745358.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device, scaler)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4011594500.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimg_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{img_id}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_classes = labels_df[label_col].nunique()\n","model = resnet_model(num_classes=num_classes, freeze_backbone=False)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","torch.backends.cudnn.benchmark = True\n","print(\"Using device:\", device)\n","\n","class_weights = compute_class_weight('balanced', classes=np.unique(train_df[label_col]), y=train_df[label_col])\n","class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n","train_criterion = nn.CrossEntropyLoss(class_weights)\n","\n","test_criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n","\n","best_acc = 0.0\n","\n","epochs = 20\n","for epoch in range(epochs):\n","    train_loss, train_correct = train_one_epoch(model, train_loader, train_criterion, optimizer, device)\n","    val_loss, val_correct = valid(model, val_loader, device, test_criterion)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_correct:.2f}%\")\n","    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_correct:.2f}%\")\n","\n","    scheduler.step(val_loss)\n","\n","    if val_correct > best_acc:\n","        best_acc = val_correct\n","        torch.save(model.state_dict(), path + 'baseline-50.pth')\n"]},{"cell_type":"markdown","id":"Ci11a7Nkv5ZZ","metadata":{"id":"Ci11a7Nkv5ZZ"},"source":["## Test model"]},{"cell_type":"code","execution_count":null,"id":"KhNNyfh5v8Yn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83993,"status":"ok","timestamp":1763460659384,"user":{"displayName":"David Thornton","userId":"09711607386999570486"},"user_tz":0},"id":"KhNNyfh5v8Yn","outputId":"89bd6628-b3fa-497e-b24a-ad1b1dca5b2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.4000    0.5000    0.4444         4\n","           1     0.7222    0.8667    0.7879        45\n","           2     0.3684    0.7778    0.5000         9\n","           3     0.8625    0.6449    0.7380       107\n","           4     0.6954    0.7778    0.7343       135\n","           5     0.7581    0.7121    0.7344       198\n","           6     0.6923    0.7200    0.7059       150\n","           7     0.8571    0.8287    0.8427       181\n","           8     0.8333    0.8730    0.8527        63\n","\n","    accuracy                         0.7578       892\n","   macro avg     0.6877    0.7445    0.7045       892\n","weighted avg     0.7681    0.7578    0.7594       892\n","\n"]}],"source":["model = resnet_model(num_classes=num_classes, freeze_backbone=False)\n","\n","model.load_state_dict(torch.load(path + 'baseline.pth'))\n","#resnet 18, stratified sampling, raw image data (pixel matric data)\n","model.to(device)\n","model.eval()\n","\n","test_loss, correct = test(model, test_loader, device, test_criterion)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}